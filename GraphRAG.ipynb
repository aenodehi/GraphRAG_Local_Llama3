{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m\n"
     ]
    }
   ],
   "source": [
    "print('m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  langchain langchain-community langchain-ollama langchain-experimental neo4j tiktoken yfiles_jupyter_graphs python-dotenv json-repair langchain-openai langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import  RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from neo4j import GraphDatabase\n",
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "import os\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from neo4j import  Driver\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or use this\n",
    "# neo4j_uri = os.getenv(\"NEO4J_URI\")\n",
    "# neo4j_username = os.getenv(\"NEO4J_USERNAME\")\n",
    "# neo4j_password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "# try:\n",
    "#     graph = Neo4jGraph(\n",
    "#         url=neo4j_uri,\n",
    "#         username=neo4j_username,\n",
    "#         password=neo4j_password\n",
    "#     )\n",
    "#     print(\"Successfully connected to Neo4j!\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Failed to connect to Neo4j: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(file_path=\"dummytext.txt\")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=24)\n",
    "documents = text_splitter.split_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9748/4058995579.py:1: LangChainDeprecationWarning: The class `OllamaFunctions` was deprecated in LangChain 0.0.64 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = OllamaFunctions(model=\"llama3.1\", temperature=0, format=\"json\")\n"
     ]
    }
   ],
   "source": [
    "llm = OllamaFunctions(model=\"llama3.1\", temperature=0, format=\"json\")\n",
    "\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphDocument(nodes=[Node(id=\"Amico'S Family\", type='Family', properties={})], relationships=[], source=Document(metadata={'source': 'dummytext.txt'}, page_content='1. The Story of Amicoâ€™s Family: A Legacy of Love and Tradition'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_graph_documents(\n",
    "    graph_documents,\n",
    "    baseEntityLabel=True,\n",
    "    include_source=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"llama3.1\",\n",
    ")\n",
    "\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    embeddings,\n",
    "    search_type=\"hybrid\",\n",
    "    node_label=\"Document\",\n",
    "    text_node_properties=[\"text\"],\n",
    "    embedding_node_property=\"embedding\"\n",
    ")\n",
    "vector_retriever = vector_index.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fulltext index created successfully.\n"
     ]
    }
   ],
   "source": [
    "driver = GraphDatabase.driver(\n",
    "        uri = os.environ[\"NEO4J_URI\"],\n",
    "        auth = (os.environ[\"NEO4J_USERNAME\"],\n",
    "                os.environ[\"NEO4J_PASSWORD\"]))\n",
    "\n",
    "def create_fulltext_index(tx):\n",
    "    query = '''\n",
    "    CREATE FULLTEXT INDEX `fulltext_entity_id` \n",
    "    FOR (n:__Entity__) \n",
    "    ON EACH [n.id];\n",
    "    '''\n",
    "    tx.run(query)\n",
    "\n",
    "# Function to execute the query\n",
    "def create_index():\n",
    "    with driver.session() as session:\n",
    "        session.execute_write(create_fulltext_index)\n",
    "        print(\"Fulltext index created successfully.\")\n",
    "\n",
    "# Call the function to create the index\n",
    "try:\n",
    "    create_index()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Close the driver connection\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entities(BaseModel):\n",
    "    \"\"\"Identifying information about entities.\"\"\"\n",
    "\n",
    "    names: list[str] = Field(\n",
    "        ...,\n",
    "        description=\"All the person, organization, or business entities that \"\n",
    "        \"appear in the text\",\n",
    "    )\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are extracting organization and person entities from the text.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Use the given format to extract information from the following \"\n",
    "            \"input: {question}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "entity_chain = llm.with_structured_output(Entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entities(names=['Nonna Lucia', 'Giovanni Caruso'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_chain.invoke(\"Who are Nonna Lucia and Giovanni Caruso?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_text_query(input: str) -> str:\n",
    "    words = [el for el in remove_lucene_chars(input).split() if el]\n",
    "    if not words:\n",
    "        return \"\"\n",
    "    full_text_query = \" AND \".join([f\"{word}~2\" for word in words])\n",
    "    print(f\"Generated Query: {full_text_query}\")\n",
    "    return full_text_query.strip()\n",
    "\n",
    "\n",
    "# Fulltext index query\n",
    "def graph_retriever(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Collects the neighborhood of entities mentioned\n",
    "    in the question\n",
    "    \"\"\"\n",
    "    result = \"\"\n",
    "    entities = entity_chain.invoke(question)\n",
    "    for entity in entities.names:\n",
    "        response = graph.query(\n",
    "            \"\"\"CALL db.index.fulltext.queryNodes('fulltext_entity_id', $query, {limit:2})\n",
    "            YIELD node,score\n",
    "            CALL {\n",
    "              WITH node\n",
    "              MATCH (node)-[r:!MENTIONS]->(neighbor)\n",
    "              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\n",
    "              UNION ALL\n",
    "              WITH node\n",
    "              MATCH (node)<-[r:!MENTIONS]-(neighbor)\n",
    "              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\n",
    "            }\n",
    "            RETURN output LIMIT 50\n",
    "            \"\"\",\n",
    "            {\"query\": entity},\n",
    "        )\n",
    "        result += \"\\n\".join([el['output'] for el in response])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonna Lucia - TAUGHT -> Amico\n",
      "Nonna Lucia - INFLUENCED -> Caponata\n",
      "Nonna Lucia - INFLUENCED -> Fresh Pasta\n",
      "Lucia - USES -> Organic And Local Ingredients\n",
      "Lucia - PRACTICES -> Sustainable Cooking Practices\n",
      "Bella Vita - OWNER -> Lucia\n"
     ]
    }
   ],
   "source": [
    "print(graph_retriever(\"Who is Nonna Lucia?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_retriever(question: str):\n",
    "    graph_data = graph_retriever(question)\n",
    "    vector_data = [el.page_content for el in vector_retriever.invoke(question)]\n",
    "    final_data = f\"\"\"Graph data:\n",
    "{graph_data}\n",
    "vector data:\n",
    "{\"#Document \". join(vector_data)}\n",
    "    \"\"\"\n",
    "    return final_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Use natural language and be concise.\n",
    "Answer:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "        {\n",
    "            \"context\": full_retriever,\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nonna Lucia is a matriarch and mentor who taught her family's recipes, particularly Amico. She was also influenced by caponata and fresh pasta.\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input=\"Who is Nonna Lucia? Did she teach anyone about restaurants or cooking?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GraphRAG_Llama3-QnTFNs1k",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
